{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josegabrielguerrero26/CSE450-machinelearning/blob/main/project3/models_team.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnGBwGVZPyyh",
        "outputId": "cf2082e9-096f-4a80-a872-742a138c0727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2560/2560 [==============================] - 17s 6ms/step - loss: 64074.1406 - mse: 64074.1406 - val_loss: 49151.7695 - val_mse: 49151.7695\n",
            "Epoch 2/200\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 50046.6719 - mse: 50046.6719 - val_loss: 43444.4219 - val_mse: 43444.4219\n",
            "Epoch 3/200\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 46137.6914 - mse: 46137.6914 - val_loss: 39545.7773 - val_mse: 39545.7773\n",
            "Epoch 4/200\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 42217.7734 - mse: 42217.7734 - val_loss: 35495.3867 - val_mse: 35495.3867\n",
            "Epoch 5/200\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 39954.1953 - mse: 39954.1953 - val_loss: 34813.0039 - val_mse: 34813.0000\n",
            "Epoch 6/200\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 38267.2773 - mse: 38267.2773 - val_loss: 36251.1875 - val_mse: 36251.1875\n",
            "Epoch 7/200\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 37070.5508 - mse: 37070.5508 - val_loss: 30172.0254 - val_mse: 30172.0254\n",
            "Epoch 8/200\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 36122.2969 - mse: 36122.2969 - val_loss: 28817.0000 - val_mse: 28816.9961\n",
            "Epoch 9/200\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 35262.2188 - mse: 35262.2188 - val_loss: 28150.7500 - val_mse: 28150.7500\n",
            "Epoch 10/200\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 34450.6914 - mse: 34450.6914 - val_loss: 29195.5664 - val_mse: 29195.5664\n",
            "Epoch 11/200\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 34242.9961 - mse: 34242.9961 - val_loss: 31436.4746 - val_mse: 31436.4746\n",
            "Epoch 12/200\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 33476.5703 - mse: 33476.5703 - val_loss: 34707.4883 - val_mse: 34707.4883\n",
            "Epoch 13/200\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 33509.7891 - mse: 33509.7891 - val_loss: 27961.8164 - val_mse: 27961.8184\n",
            "Epoch 14/200\n",
            "2550/2560 [============================>.] - ETA: 0s - loss: 33291.0508 - mse: 33291.0508"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Dense, BatchNormalization, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Read data\n",
        "bikes = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv')\n",
        "\n",
        "# Handle missing values\n",
        "bikes['hr'] = bikes['hr'].fillna(bikes['hr'].shift(1) + 1)\n",
        "\n",
        "# Create total_users feature\n",
        "bikes[\"total_users\"] = bikes[\"casual\"] + bikes[\"registered\"]\n",
        "\n",
        "# Split features and target\n",
        "y = bikes['total_users']\n",
        "X = bikes.drop(columns=['casual', 'registered', 'total_users', 'dteday'])\n",
        "\n",
        "# Normalize data\n",
        "norm = MinMaxScaler().fit(X)\n",
        "X_norm = norm.transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define model\n",
        "model = Sequential([\n",
        "    Dense(512, input_dim=X_train.shape[1], activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "optimizer = Adam(learning_rate=0.002)\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=['mse'])\n",
        "\n",
        "# Early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=30)\n",
        "\n",
        "# Model training\n",
        "history = model.fit(X_train, y_train, epochs=200, validation_split=0.35, batch_size=20,\n",
        "                    callbacks=[early_stop], shuffle=True, verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "predictions = model.predict(X_test)\n",
        "result = mean_squared_error(y_test, predictions, squared=False)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(f'MSE: {result:.3f}, R2: {r2:.3f}')\n",
        "\n",
        "# Save predictions\n",
        "bikesTest = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/biking_holdout_test_mini.csv')\n",
        "bikesTest = bikesTest.drop(columns=['dteday'])\n",
        "\n",
        "bikesTest_norm = norm.transform(bikesTest)\n",
        "holdout_predictions = model.predict(bikesTest_norm)\n",
        "rounded_predictions = np.round(holdout_predictions)\n",
        "np.savetxt(\"team1-module4-predictions.csv\", rounded_predictions, delimiter=\",\", header=\"predictions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCF1Xqd1U5H9",
        "outputId": "dbef982b-1500-48ec-a7d7-3283261d79ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2560/2560 [==============================] - 10s 3ms/step - loss: 84560.7812 - mse: 84560.7812 - val_loss: 65912.5703 - val_mse: 65912.5703\n",
            "Epoch 2/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 63098.7969 - mse: 63098.7969 - val_loss: 52416.6680 - val_mse: 52416.6719\n",
            "Epoch 3/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 55594.2773 - mse: 55594.2773 - val_loss: 48142.3789 - val_mse: 48142.3789\n",
            "Epoch 4/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 51877.3711 - mse: 51877.3711 - val_loss: 46380.6680 - val_mse: 46380.6680\n",
            "Epoch 5/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 49821.0391 - mse: 49821.0391 - val_loss: 45149.8398 - val_mse: 45149.8398\n",
            "Epoch 6/100\n",
            "2560/2560 [==============================] - 7s 3ms/step - loss: 48402.6016 - mse: 48402.6016 - val_loss: 43729.2773 - val_mse: 43729.2773\n",
            "Epoch 7/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 47414.1445 - mse: 47414.1445 - val_loss: 42909.8984 - val_mse: 42909.8906\n",
            "Epoch 8/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 46107.7891 - mse: 46107.7891 - val_loss: 40772.5625 - val_mse: 40772.5625\n",
            "Epoch 9/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 44944.0547 - mse: 44944.0547 - val_loss: 39240.8867 - val_mse: 39240.8867\n",
            "Epoch 10/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 43351.3789 - mse: 43351.3789 - val_loss: 37404.6172 - val_mse: 37404.6172\n",
            "Epoch 11/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 41461.3242 - mse: 41461.3242 - val_loss: 35399.6211 - val_mse: 35399.6211\n",
            "Epoch 12/100\n",
            "2560/2560 [==============================] - 14s 5ms/step - loss: 39952.4453 - mse: 39952.4453 - val_loss: 33946.0508 - val_mse: 33946.0547\n",
            "Epoch 13/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 38429.5469 - mse: 38429.5469 - val_loss: 33250.1406 - val_mse: 33250.1406\n",
            "Epoch 14/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 37325.4219 - mse: 37325.4219 - val_loss: 31830.6230 - val_mse: 31830.6230\n",
            "Epoch 15/100\n",
            "2560/2560 [==============================] - 11s 4ms/step - loss: 36585.6992 - mse: 36585.6992 - val_loss: 31493.4746 - val_mse: 31493.4766\n",
            "Epoch 16/100\n",
            "2560/2560 [==============================] - 13s 5ms/step - loss: 35940.4961 - mse: 35940.4961 - val_loss: 31064.1562 - val_mse: 31064.1562\n",
            "Epoch 17/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 35432.2695 - mse: 35432.2695 - val_loss: 30604.3477 - val_mse: 30604.3477\n",
            "Epoch 18/100\n",
            "2560/2560 [==============================] - 12s 5ms/step - loss: 34897.1133 - mse: 34897.1133 - val_loss: 30262.5039 - val_mse: 30262.5020\n",
            "Epoch 19/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 34681.6914 - mse: 34681.6914 - val_loss: 30362.4727 - val_mse: 30362.4746\n",
            "Epoch 20/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 34060.2031 - mse: 34060.2031 - val_loss: 29808.8379 - val_mse: 29808.8379\n",
            "Epoch 21/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 33654.2891 - mse: 33654.2891 - val_loss: 29003.3809 - val_mse: 29003.3809\n",
            "Epoch 22/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 33517.2305 - mse: 33517.2305 - val_loss: 29324.5645 - val_mse: 29324.5645\n",
            "Epoch 23/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 33357.3984 - mse: 33357.3984 - val_loss: 29240.1387 - val_mse: 29240.1387\n",
            "Epoch 24/100\n",
            "2560/2560 [==============================] - 11s 4ms/step - loss: 33085.8320 - mse: 33085.8320 - val_loss: 28704.0664 - val_mse: 28704.0664\n",
            "Epoch 25/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 32832.8789 - mse: 32832.8789 - val_loss: 28740.5742 - val_mse: 28740.5742\n",
            "Epoch 26/100\n",
            "2560/2560 [==============================] - 11s 4ms/step - loss: 32570.0293 - mse: 32570.0293 - val_loss: 28268.8672 - val_mse: 28268.8672\n",
            "Epoch 27/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 32440.9238 - mse: 32440.9238 - val_loss: 27994.5762 - val_mse: 27994.5762\n",
            "Epoch 28/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 32194.4316 - mse: 32194.4316 - val_loss: 27448.4023 - val_mse: 27448.4023\n",
            "Epoch 29/100\n",
            "2560/2560 [==============================] - 11s 4ms/step - loss: 31962.2969 - mse: 31962.2969 - val_loss: 27219.7285 - val_mse: 27219.7285\n",
            "Epoch 30/100\n",
            "2560/2560 [==============================] - 11s 4ms/step - loss: 31705.2637 - mse: 31705.2637 - val_loss: 27938.4766 - val_mse: 27938.4766\n",
            "Epoch 31/100\n",
            "2560/2560 [==============================] - 13s 5ms/step - loss: 31734.6484 - mse: 31734.6523 - val_loss: 27492.0938 - val_mse: 27492.0938\n",
            "Epoch 32/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 31388.2500 - mse: 31388.2500 - val_loss: 27208.5840 - val_mse: 27208.5840\n",
            "Epoch 33/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 31358.7324 - mse: 31358.7324 - val_loss: 26873.1934 - val_mse: 26873.1934\n",
            "Epoch 34/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 31409.7441 - mse: 31409.7441 - val_loss: 27302.1934 - val_mse: 27302.1934\n",
            "Epoch 35/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 31086.8691 - mse: 31086.8691 - val_loss: 27184.5566 - val_mse: 27184.5566\n",
            "Epoch 36/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 31157.0879 - mse: 31157.0879 - val_loss: 27037.1270 - val_mse: 27037.1270\n",
            "Epoch 37/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 30917.6289 - mse: 30917.6309 - val_loss: 26828.3223 - val_mse: 26828.3223\n",
            "Epoch 38/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 30957.7227 - mse: 30957.7227 - val_loss: 26388.3418 - val_mse: 26388.3418\n",
            "Epoch 39/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 30573.6133 - mse: 30573.6133 - val_loss: 26540.3496 - val_mse: 26540.3496\n",
            "Epoch 40/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30867.1426 - mse: 30867.1426 - val_loss: 26601.1465 - val_mse: 26601.1465\n",
            "Epoch 41/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 30679.1465 - mse: 30679.1465 - val_loss: 26884.2539 - val_mse: 26884.2539\n",
            "Epoch 42/100\n",
            "2560/2560 [==============================] - 11s 4ms/step - loss: 30418.4258 - mse: 30418.4258 - val_loss: 26683.0703 - val_mse: 26683.0703\n",
            "Epoch 43/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30365.9707 - mse: 30365.9707 - val_loss: 26801.7266 - val_mse: 26801.7266\n",
            "Epoch 44/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 30550.2676 - mse: 30550.2676 - val_loss: 26717.5879 - val_mse: 26717.5879\n",
            "Epoch 45/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30406.8164 - mse: 30406.8164 - val_loss: 26584.4355 - val_mse: 26584.4355\n",
            "Epoch 46/100\n",
            "2560/2560 [==============================] - 11s 4ms/step - loss: 30524.6250 - mse: 30524.6250 - val_loss: 26905.1660 - val_mse: 26905.1660\n",
            "Epoch 47/100\n",
            "2560/2560 [==============================] - 12s 5ms/step - loss: 30403.6426 - mse: 30403.6426 - val_loss: 26264.9258 - val_mse: 26264.9258\n",
            "Epoch 48/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30422.9238 - mse: 30422.9238 - val_loss: 26295.3555 - val_mse: 26295.3555\n",
            "Epoch 49/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 30171.6543 - mse: 30171.6543 - val_loss: 26534.2754 - val_mse: 26534.2754\n",
            "Epoch 50/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30007.5449 - mse: 30007.5449 - val_loss: 26655.0527 - val_mse: 26655.0527\n",
            "Epoch 51/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 30179.7461 - mse: 30179.7461 - val_loss: 27006.7969 - val_mse: 27006.7949\n",
            "Epoch 52/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 29962.9766 - mse: 29962.9766 - val_loss: 26546.8145 - val_mse: 26546.8145\n",
            "Epoch 53/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 29979.7500 - mse: 29979.7500 - val_loss: 26392.8887 - val_mse: 26392.8887\n",
            "Epoch 54/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 30019.2617 - mse: 30019.2617 - val_loss: 26542.7109 - val_mse: 26542.7109\n",
            "Epoch 55/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 29860.8008 - mse: 29860.8027 - val_loss: 26560.9180 - val_mse: 26560.9180\n",
            "Epoch 56/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 29938.0977 - mse: 29938.0977 - val_loss: 26960.4961 - val_mse: 26960.4961\n",
            "Epoch 57/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 29811.1523 - mse: 29811.1523 - val_loss: 26381.0723 - val_mse: 26381.0723\n",
            "Epoch 58/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 29943.6250 - mse: 29943.6250 - val_loss: 26701.3203 - val_mse: 26701.3184\n",
            "Epoch 59/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 29829.9746 - mse: 29829.9746 - val_loss: 26798.7344 - val_mse: 26798.7344\n",
            "Epoch 60/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 29647.8301 - mse: 29647.8301 - val_loss: 26673.3008 - val_mse: 26673.3008\n",
            "Epoch 61/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 29650.3926 - mse: 29650.3926 - val_loss: 26764.4668 - val_mse: 26764.4668\n",
            "Epoch 62/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 29842.9922 - mse: 29842.9902 - val_loss: 27057.5273 - val_mse: 27057.5273\n",
            "Epoch 63/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 29604.9688 - mse: 29604.9688 - val_loss: 26840.2324 - val_mse: 26840.2305\n",
            "Epoch 64/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 29538.3984 - mse: 29538.3984 - val_loss: 26831.9805 - val_mse: 26831.9805\n",
            "Epoch 65/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 29508.0781 - mse: 29508.0781 - val_loss: 26573.5918 - val_mse: 26573.5918\n",
            "Epoch 66/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 29777.0195 - mse: 29777.0195 - val_loss: 26457.4297 - val_mse: 26457.4297\n",
            "Epoch 67/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 29652.1621 - mse: 29652.1621 - val_loss: 26719.0332 - val_mse: 26719.0332\n",
            "Epoch 68/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 29566.5898 - mse: 29566.5898 - val_loss: 26611.5156 - val_mse: 26611.5156\n",
            "Epoch 69/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 29559.7266 - mse: 29559.7266 - val_loss: 26463.5781 - val_mse: 26463.5781\n",
            "Epoch 70/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 29505.7676 - mse: 29505.7676 - val_loss: 27079.2129 - val_mse: 27079.2129\n",
            "Epoch 71/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 29391.9766 - mse: 29391.9766 - val_loss: 26632.5098 - val_mse: 26632.5098\n",
            "Epoch 72/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 29480.3398 - mse: 29480.3379 - val_loss: 27009.7246 - val_mse: 27009.7246\n",
            "Epoch 73/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 29415.8691 - mse: 29415.8691 - val_loss: 26834.9219 - val_mse: 26834.9219\n",
            "Epoch 74/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 29390.8086 - mse: 29390.8086 - val_loss: 26747.2539 - val_mse: 26747.2500\n",
            "Epoch 75/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 29295.3105 - mse: 29295.3105 - val_loss: 27047.8496 - val_mse: 27047.8555\n",
            "Epoch 76/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 29412.1816 - mse: 29412.1816 - val_loss: 27065.3184 - val_mse: 27065.3184\n",
            "Epoch 77/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 29331.1426 - mse: 29331.1426 - val_loss: 27089.5449 - val_mse: 27089.5449\n",
            "1055/1055 [==============================] - 2s 1ms/step\n",
            "MSE: 164.736, R2: 0.769\n",
            "12/12 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "from numpy.random import randint\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Read data\n",
        "bikes = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv')\n",
        "\n",
        "# Handle missing values\n",
        "for row in bikes[bikes['hr'].isnull()].index.values:\n",
        "    bikes.loc[row,'hr'] = bikes.loc[row-1,'hr']+1\n",
        "\n",
        "# Create total_users feature\n",
        "bikes[\"total_users\"] = bikes[\"casual\"] + bikes[\"registered\"]\n",
        "\n",
        "# Split features and target\n",
        "y = bikes['total_users']\n",
        "X = bikes.drop(columns=['casual', 'registered', 'total_users', 'dteday'])\n",
        "\n",
        "# Normalize data\n",
        "norm = MinMaxScaler().fit(X)\n",
        "X_norm = norm.transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define model\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=len(X_train[1]), activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=['mse'])\n",
        "\n",
        "# Early stopping\n",
        "early_stop = EarlyStopping(monitor='val_mse', patience=30)\n",
        "\n",
        "# Model training\n",
        "history = model.fit(X_train, y_train, epochs=100, validation_split=0.35, batch_size=20,\n",
        "                    callbacks=[early_stop], shuffle=False, verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "predictions = model.predict(X_test)\n",
        "result = mean_squared_error(y_test, predictions, squared=False)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(f'MSE: {result:.3f}, R2: {r2:.3f}')\n",
        "\n",
        "# Save predictions\n",
        "bikesTest = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/biking_holdout_test_mini.csv')\n",
        "bikesTest = bikesTest.drop(columns=['dteday'])\n",
        "bikesTest_norm = norm.transform(bikesTest)\n",
        "holdout_predictions = model.predict(bikesTest_norm)\n",
        "rounded_predictions = np.round(holdout_predictions)\n",
        "np.savetxt(\"team1-module4-predictions.csv\", rounded_predictions, delimiter=\",\", header=\"predictions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import randint\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Read data\n",
        "bikes = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv')\n",
        "\n",
        "# Handle missing values\n",
        "bikes['hr'] = bikes['hr'].fillna(bikes['hr'].shift(1) + 1)\n",
        "\n",
        "# Create total_users feature\n",
        "bikes[\"total_users\"] = bikes[\"casual\"] + bikes[\"registered\"]\n",
        "\n",
        "# Split features and target\n",
        "y = bikes['total_users']\n",
        "X = bikes.drop(columns=['casual', 'registered', 'total_users', 'dteday'])\n",
        "\n",
        "# Normalize data\n",
        "norm = MinMaxScaler().fit(X)\n",
        "X_norm = norm.transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define model\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=['mse'])\n",
        "\n",
        "# Early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=30)\n",
        "\n",
        "# Model training\n",
        "history = model.fit(X_train, y_train, epochs=100, validation_split=0.35, batch_size=20,\n",
        "                    callbacks=[early_stop], shuffle=True, verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "predictions = model.predict(X_test)\n",
        "result = mean_squared_error(y_test, predictions, squared=False)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(f'MSE: {result:.3f}, R2: {r2:.3f}')\n",
        "\n",
        "# Save predictions\n",
        "bikesTest = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/biking_holdout_test_mini.csv')\n",
        "bikesTest = bikesTest.drop(columns=['dteday'])\n",
        "bikesTest_norm = norm.transform(bikesTest)\n",
        "holdout_predictions = model.predict(bikesTest_norm)\n",
        "rounded_predictions = np.round(holdout_predictions)\n",
        "np.savetxt(\"team1-module4-predictions.csv\", rounded_predictions, delimiter=\",\", header=\"predictions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bru3FzfezrCG",
        "outputId": "ec990e81-3adb-40e5-d2b3-2c8fedc3129b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 92454.2969 - mse: 92454.2969 - val_loss: 74368.6719 - val_mse: 74368.6719\n",
            "Epoch 2/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 72490.7891 - mse: 72490.7891 - val_loss: 63528.7266 - val_mse: 63528.7266\n",
            "Epoch 3/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 63979.2109 - mse: 63979.2109 - val_loss: 56303.7539 - val_mse: 56303.7539\n",
            "Epoch 4/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 58494.8477 - mse: 58494.8477 - val_loss: 51856.0156 - val_mse: 51856.0156\n",
            "Epoch 5/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 54982.1875 - mse: 54982.1875 - val_loss: 49624.3398 - val_mse: 49624.3398\n",
            "Epoch 6/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 52742.8711 - mse: 52742.8711 - val_loss: 48568.7070 - val_mse: 48568.7070\n",
            "Epoch 7/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 51337.9766 - mse: 51337.9766 - val_loss: 47071.2734 - val_mse: 47071.2734\n",
            "Epoch 8/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 50095.4141 - mse: 50095.4141 - val_loss: 45807.4336 - val_mse: 45807.4336\n",
            "Epoch 9/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 49314.3398 - mse: 49314.3398 - val_loss: 44958.4961 - val_mse: 44958.4961\n",
            "Epoch 10/100\n",
            "2560/2560 [==============================] - 7s 3ms/step - loss: 48572.8203 - mse: 48572.8242 - val_loss: 44006.7422 - val_mse: 44006.7422\n",
            "Epoch 11/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 47963.6328 - mse: 47963.6328 - val_loss: 43566.2188 - val_mse: 43566.2188\n",
            "Epoch 12/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 47325.1406 - mse: 47325.1406 - val_loss: 43475.7930 - val_mse: 43475.7930\n",
            "Epoch 13/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 46664.2773 - mse: 46664.2773 - val_loss: 42953.2773 - val_mse: 42953.2773\n",
            "Epoch 14/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 45902.0508 - mse: 45902.0508 - val_loss: 41446.7656 - val_mse: 41446.7656\n",
            "Epoch 15/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 45586.0000 - mse: 45586.0000 - val_loss: 41353.0898 - val_mse: 41353.0898\n",
            "Epoch 16/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 45167.2812 - mse: 45167.2812 - val_loss: 40518.0664 - val_mse: 40518.0664\n",
            "Epoch 17/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 44729.1289 - mse: 44729.1289 - val_loss: 40356.0273 - val_mse: 40356.0273\n",
            "Epoch 18/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 44273.5586 - mse: 44273.5586 - val_loss: 39951.8750 - val_mse: 39951.8750\n",
            "Epoch 19/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 44108.2617 - mse: 44108.2617 - val_loss: 39170.4844 - val_mse: 39170.4844\n",
            "Epoch 20/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 43590.5117 - mse: 43590.5156 - val_loss: 39717.5000 - val_mse: 39717.5000\n",
            "Epoch 21/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 43240.4180 - mse: 43240.4180 - val_loss: 39919.1523 - val_mse: 39919.1523\n",
            "Epoch 22/100\n",
            "2560/2560 [==============================] - 11s 4ms/step - loss: 42908.1992 - mse: 42908.1992 - val_loss: 38494.7773 - val_mse: 38494.7773\n",
            "Epoch 23/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 42533.6484 - mse: 42533.6445 - val_loss: 37277.7500 - val_mse: 37277.7500\n",
            "Epoch 24/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 41954.5039 - mse: 41954.5039 - val_loss: 36842.5469 - val_mse: 36842.5469\n",
            "Epoch 25/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 41687.0859 - mse: 41687.0859 - val_loss: 36468.2930 - val_mse: 36468.2930\n",
            "Epoch 26/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 41112.6250 - mse: 41112.6250 - val_loss: 35979.3125 - val_mse: 35979.3125\n",
            "Epoch 27/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 40278.4102 - mse: 40278.4102 - val_loss: 35432.7148 - val_mse: 35432.7148\n",
            "Epoch 28/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 39982.5039 - mse: 39982.5039 - val_loss: 35587.8320 - val_mse: 35587.8320\n",
            "Epoch 29/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 39229.0117 - mse: 39229.0117 - val_loss: 34453.0547 - val_mse: 34453.0547\n",
            "Epoch 30/100\n",
            "2560/2560 [==============================] - 7s 3ms/step - loss: 38496.2344 - mse: 38496.2344 - val_loss: 33964.8867 - val_mse: 33964.8867\n",
            "Epoch 31/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 37905.1406 - mse: 37905.1406 - val_loss: 33679.8906 - val_mse: 33679.8906\n",
            "Epoch 32/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 37370.7656 - mse: 37370.7656 - val_loss: 32585.9414 - val_mse: 32585.9434\n",
            "Epoch 33/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 36852.4062 - mse: 36852.4102 - val_loss: 32183.2559 - val_mse: 32183.2559\n",
            "Epoch 34/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 36249.6836 - mse: 36249.6836 - val_loss: 33298.1055 - val_mse: 33298.1055\n",
            "Epoch 35/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 36067.7383 - mse: 36067.7383 - val_loss: 32990.3906 - val_mse: 32990.3906\n",
            "Epoch 36/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 35614.3633 - mse: 35614.3633 - val_loss: 31406.8203 - val_mse: 31406.8203\n",
            "Epoch 37/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 35280.8711 - mse: 35280.8711 - val_loss: 30627.9785 - val_mse: 30627.9785\n",
            "Epoch 38/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 35301.4297 - mse: 35301.4297 - val_loss: 30907.7871 - val_mse: 30907.7871\n",
            "Epoch 39/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 34690.7930 - mse: 34690.7930 - val_loss: 30599.2129 - val_mse: 30599.2129\n",
            "Epoch 40/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 34547.6016 - mse: 34547.6016 - val_loss: 30378.3164 - val_mse: 30378.3164\n",
            "Epoch 41/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 34220.4375 - mse: 34220.4375 - val_loss: 30346.7539 - val_mse: 30346.7539\n",
            "Epoch 42/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 33965.4883 - mse: 33965.4883 - val_loss: 30453.6289 - val_mse: 30453.6289\n",
            "Epoch 43/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 34110.6641 - mse: 34110.6641 - val_loss: 30042.8535 - val_mse: 30042.8535\n",
            "Epoch 44/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 33651.9883 - mse: 33651.9883 - val_loss: 30011.0039 - val_mse: 30011.0039\n",
            "Epoch 45/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 33857.6602 - mse: 33857.6602 - val_loss: 30050.5781 - val_mse: 30050.5781\n",
            "Epoch 46/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 33196.6914 - mse: 33196.6914 - val_loss: 29604.5312 - val_mse: 29604.5312\n",
            "Epoch 47/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 33277.1680 - mse: 33277.1680 - val_loss: 29724.9980 - val_mse: 29724.9980\n",
            "Epoch 48/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 33213.0352 - mse: 33213.0352 - val_loss: 29850.3457 - val_mse: 29850.3457\n",
            "Epoch 49/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 33059.2070 - mse: 33059.2070 - val_loss: 29558.9238 - val_mse: 29558.9277\n",
            "Epoch 50/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 32848.4219 - mse: 32848.4219 - val_loss: 30267.9082 - val_mse: 30267.9082\n",
            "Epoch 51/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 32548.3633 - mse: 32548.3633 - val_loss: 28721.7148 - val_mse: 28721.7148\n",
            "Epoch 52/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 32286.3633 - mse: 32286.3633 - val_loss: 28825.1211 - val_mse: 28825.1211\n",
            "Epoch 53/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 32556.2031 - mse: 32556.2070 - val_loss: 28714.4609 - val_mse: 28714.4609\n",
            "Epoch 54/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 32326.2051 - mse: 32326.2051 - val_loss: 29038.0742 - val_mse: 29038.0742\n",
            "Epoch 55/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 32230.4004 - mse: 32230.4004 - val_loss: 28472.4590 - val_mse: 28472.4590\n",
            "Epoch 56/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 32290.2383 - mse: 32290.2344 - val_loss: 28292.7773 - val_mse: 28292.7773\n",
            "Epoch 57/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 32169.8105 - mse: 32169.8105 - val_loss: 27840.6719 - val_mse: 27840.6719\n",
            "Epoch 58/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 31937.9961 - mse: 31937.9961 - val_loss: 28544.3145 - val_mse: 28544.3145\n",
            "Epoch 59/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 31932.5156 - mse: 31932.5156 - val_loss: 27742.8145 - val_mse: 27742.8125\n",
            "Epoch 60/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 31736.8594 - mse: 31736.8574 - val_loss: 27763.3320 - val_mse: 27763.3320\n",
            "Epoch 61/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 31833.5762 - mse: 31833.5762 - val_loss: 27748.5137 - val_mse: 27748.5137\n",
            "Epoch 62/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 31751.0547 - mse: 31751.0547 - val_loss: 27877.4199 - val_mse: 27877.4160\n",
            "Epoch 63/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 31648.0488 - mse: 31648.0488 - val_loss: 27868.7305 - val_mse: 27868.7305\n",
            "Epoch 64/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 31350.1758 - mse: 31350.1758 - val_loss: 27572.9336 - val_mse: 27572.9336\n",
            "Epoch 65/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 31261.9883 - mse: 31261.9883 - val_loss: 27566.7402 - val_mse: 27566.7402\n",
            "Epoch 66/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 31406.9375 - mse: 31406.9316 - val_loss: 27914.3105 - val_mse: 27914.3105\n",
            "Epoch 67/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 31154.7031 - mse: 31154.7031 - val_loss: 27998.1660 - val_mse: 27998.1660\n",
            "Epoch 68/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 31464.0977 - mse: 31464.0977 - val_loss: 26965.5664 - val_mse: 26965.5664\n",
            "Epoch 69/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 31004.7598 - mse: 31004.7637 - val_loss: 27143.2109 - val_mse: 27143.2109\n",
            "Epoch 70/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30979.4219 - mse: 30979.4219 - val_loss: 27527.5469 - val_mse: 27527.5469\n",
            "Epoch 71/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 31099.8027 - mse: 31099.8027 - val_loss: 26875.8516 - val_mse: 26875.8516\n",
            "Epoch 72/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 31068.0039 - mse: 31068.0039 - val_loss: 27007.5078 - val_mse: 27007.5078\n",
            "Epoch 73/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30848.3203 - mse: 30848.3203 - val_loss: 27203.2676 - val_mse: 27203.2676\n",
            "Epoch 74/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 30655.5352 - mse: 30655.5352 - val_loss: 27331.7441 - val_mse: 27331.7441\n",
            "Epoch 75/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 30855.5059 - mse: 30855.5059 - val_loss: 26858.8457 - val_mse: 26858.8457\n",
            "Epoch 76/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30708.5449 - mse: 30708.5449 - val_loss: 26913.9629 - val_mse: 26913.9629\n",
            "Epoch 77/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30456.6445 - mse: 30456.6445 - val_loss: 26558.8105 - val_mse: 26558.8105\n",
            "Epoch 78/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 30406.8418 - mse: 30406.8379 - val_loss: 26536.0762 - val_mse: 26536.0762\n",
            "Epoch 79/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30265.7031 - mse: 30265.7031 - val_loss: 27272.8945 - val_mse: 27272.8945\n",
            "Epoch 80/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30355.4551 - mse: 30355.4551 - val_loss: 26618.8633 - val_mse: 26618.8633\n",
            "Epoch 81/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30408.5410 - mse: 30408.5410 - val_loss: 27627.7227 - val_mse: 27627.7227\n",
            "Epoch 82/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 30306.0645 - mse: 30306.0645 - val_loss: 26786.0254 - val_mse: 26786.0254\n",
            "Epoch 83/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30417.7520 - mse: 30417.7520 - val_loss: 26897.7520 - val_mse: 26897.7520\n",
            "Epoch 84/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 30082.4551 - mse: 30082.4551 - val_loss: 26363.8184 - val_mse: 26363.8184\n",
            "Epoch 85/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 30162.4766 - mse: 30162.4766 - val_loss: 26974.0684 - val_mse: 26974.0684\n",
            "Epoch 86/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30172.5586 - mse: 30172.5586 - val_loss: 26414.0723 - val_mse: 26414.0723\n",
            "Epoch 87/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 30097.3867 - mse: 30097.3867 - val_loss: 26433.5879 - val_mse: 26433.5879\n",
            "Epoch 88/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 30012.5371 - mse: 30012.5371 - val_loss: 26751.5469 - val_mse: 26751.5469\n",
            "Epoch 89/100\n",
            "2560/2560 [==============================] - 10s 4ms/step - loss: 29746.7441 - mse: 29746.7441 - val_loss: 26570.6152 - val_mse: 26570.6152\n",
            "Epoch 90/100\n",
            "2560/2560 [==============================] - 9s 3ms/step - loss: 30001.7441 - mse: 30001.7402 - val_loss: 26296.1484 - val_mse: 26296.1484\n",
            "Epoch 91/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 29846.2539 - mse: 29846.2539 - val_loss: 26531.1738 - val_mse: 26531.1738\n",
            "Epoch 92/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 29981.7168 - mse: 29981.7168 - val_loss: 26242.6895 - val_mse: 26242.6895\n",
            "Epoch 93/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 30009.6934 - mse: 30009.6973 - val_loss: 26297.9668 - val_mse: 26297.9648\n",
            "Epoch 94/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 29518.1836 - mse: 29518.1836 - val_loss: 26209.8496 - val_mse: 26209.8496\n",
            "Epoch 95/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 29685.5488 - mse: 29685.5488 - val_loss: 26032.3438 - val_mse: 26032.3438\n",
            "Epoch 96/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 29655.0332 - mse: 29655.0332 - val_loss: 26321.6035 - val_mse: 26321.6035\n",
            "Epoch 97/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 29638.9336 - mse: 29638.9336 - val_loss: 26280.5898 - val_mse: 26280.5898\n",
            "Epoch 98/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 29582.4375 - mse: 29582.4375 - val_loss: 26249.4160 - val_mse: 26249.4160\n",
            "Epoch 99/100\n",
            "2560/2560 [==============================] - 9s 4ms/step - loss: 29683.9980 - mse: 29683.9961 - val_loss: 26085.2207 - val_mse: 26085.2207\n",
            "Epoch 100/100\n",
            "2560/2560 [==============================] - 8s 3ms/step - loss: 29462.2578 - mse: 29462.2559 - val_loss: 25974.5508 - val_mse: 25974.5508\n",
            "1055/1055 [==============================] - 2s 2ms/step\n",
            "MSE: 161.011, R2: 0.779\n",
            "12/12 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzYpgNbCf3dX",
        "outputId": "1112d560-0887-4456-bcd8-b93b5d608553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 95684.5469 - mse: 95684.5469 - val_loss: 74672.7188 - val_mse: 74672.7188\n",
            "Epoch 2/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 72595.8438 - mse: 72595.8359 - val_loss: 67113.4297 - val_mse: 67113.4297\n",
            "Epoch 3/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 64323.5352 - mse: 64323.5352 - val_loss: 58003.4648 - val_mse: 58003.4648\n",
            "Epoch 4/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 57863.9180 - mse: 57863.9180 - val_loss: 53080.5859 - val_mse: 53080.5859\n",
            "Epoch 5/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 54371.4766 - mse: 54371.4766 - val_loss: 50050.2891 - val_mse: 50050.2891\n",
            "Epoch 6/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 52189.3633 - mse: 52189.3633 - val_loss: 48427.7305 - val_mse: 48427.7305\n",
            "Epoch 7/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 50405.8594 - mse: 50405.8594 - val_loss: 46971.8125 - val_mse: 46971.8125\n",
            "Epoch 8/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 49427.2812 - mse: 49427.2812 - val_loss: 46729.9688 - val_mse: 46729.9688\n",
            "Epoch 9/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 48298.9492 - mse: 48298.9492 - val_loss: 44711.1133 - val_mse: 44711.1055\n",
            "Epoch 10/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 47295.9062 - mse: 47295.9062 - val_loss: 43859.6719 - val_mse: 43859.6719\n",
            "Epoch 11/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 46275.4766 - mse: 46275.4766 - val_loss: 42500.4297 - val_mse: 42500.4297\n",
            "Epoch 12/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 45055.7461 - mse: 45055.7461 - val_loss: 41624.5039 - val_mse: 41624.5039\n",
            "Epoch 13/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 44294.1523 - mse: 44294.1523 - val_loss: 40269.9688 - val_mse: 40269.9688\n",
            "Epoch 14/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 42879.0859 - mse: 42879.0859 - val_loss: 39358.8320 - val_mse: 39358.8320\n",
            "Epoch 15/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 41802.9141 - mse: 41802.9141 - val_loss: 38273.9883 - val_mse: 38273.9883\n",
            "Epoch 16/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 40457.3359 - mse: 40457.3359 - val_loss: 37426.1406 - val_mse: 37426.1445\n",
            "Epoch 17/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 39095.8906 - mse: 39095.8906 - val_loss: 35046.4297 - val_mse: 35046.4297\n",
            "Epoch 18/200\n",
            "2560/2560 [==============================] - 17s 6ms/step - loss: 37620.9766 - mse: 37620.9766 - val_loss: 33901.1016 - val_mse: 33901.1016\n",
            "Epoch 19/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 36701.2930 - mse: 36701.2930 - val_loss: 32567.9043 - val_mse: 32567.9043\n",
            "Epoch 20/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 35596.2852 - mse: 35596.2852 - val_loss: 31539.1699 - val_mse: 31539.1699\n",
            "Epoch 21/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 34526.3555 - mse: 34526.3555 - val_loss: 31288.6934 - val_mse: 31288.6934\n",
            "Epoch 22/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 34000.7617 - mse: 34000.7617 - val_loss: 30721.1660 - val_mse: 30721.1660\n",
            "Epoch 23/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 33518.1992 - mse: 33518.1992 - val_loss: 29868.0391 - val_mse: 29868.0391\n",
            "Epoch 24/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 33216.1523 - mse: 33216.1523 - val_loss: 29533.3730 - val_mse: 29533.3730\n",
            "Epoch 25/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 32633.8262 - mse: 32633.8262 - val_loss: 28973.7891 - val_mse: 28973.7891\n",
            "Epoch 26/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 32183.8887 - mse: 32183.8887 - val_loss: 29180.6250 - val_mse: 29180.6211\n",
            "Epoch 27/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 32075.1836 - mse: 32075.1836 - val_loss: 28999.3301 - val_mse: 28999.3301\n",
            "Epoch 28/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 31580.8887 - mse: 31580.8887 - val_loss: 28531.0605 - val_mse: 28531.0605\n",
            "Epoch 29/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 31422.4648 - mse: 31422.4648 - val_loss: 28745.2500 - val_mse: 28745.2500\n",
            "Epoch 30/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 31189.0215 - mse: 31189.0215 - val_loss: 27938.9160 - val_mse: 27938.9160\n",
            "Epoch 31/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 30927.3164 - mse: 30927.3164 - val_loss: 28268.9277 - val_mse: 28268.9277\n",
            "Epoch 32/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 30783.8711 - mse: 30783.8711 - val_loss: 28120.0410 - val_mse: 28120.0410\n",
            "Epoch 33/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 30689.7129 - mse: 30689.7129 - val_loss: 28005.0039 - val_mse: 28005.0039\n",
            "Epoch 34/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 30268.9551 - mse: 30268.9551 - val_loss: 28064.3535 - val_mse: 28064.3535\n",
            "Epoch 35/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 30253.2402 - mse: 30253.2363 - val_loss: 27715.3184 - val_mse: 27715.3184\n",
            "Epoch 36/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 30134.5332 - mse: 30134.5332 - val_loss: 27526.0039 - val_mse: 27526.0039\n",
            "Epoch 37/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 30236.2598 - mse: 30236.2637 - val_loss: 27150.2363 - val_mse: 27150.2363\n",
            "Epoch 38/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 29958.6172 - mse: 29958.6172 - val_loss: 27308.4629 - val_mse: 27308.4629\n",
            "Epoch 39/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 29635.9512 - mse: 29635.9512 - val_loss: 26626.1914 - val_mse: 26626.1914\n",
            "Epoch 40/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 29514.3945 - mse: 29514.4004 - val_loss: 26835.6680 - val_mse: 26835.6680\n",
            "Epoch 41/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 29577.0312 - mse: 29577.0312 - val_loss: 27007.3125 - val_mse: 27007.3125\n",
            "Epoch 42/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 29294.9805 - mse: 29294.9805 - val_loss: 27421.2676 - val_mse: 27421.2676\n",
            "Epoch 43/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 29164.5703 - mse: 29164.5703 - val_loss: 26631.1250 - val_mse: 26631.1250\n",
            "Epoch 44/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 28963.0254 - mse: 28963.0312 - val_loss: 26605.6289 - val_mse: 26605.6289\n",
            "Epoch 45/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 29033.4863 - mse: 29033.4863 - val_loss: 26230.4570 - val_mse: 26230.4570\n",
            "Epoch 46/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 28893.5078 - mse: 28893.5078 - val_loss: 27844.9902 - val_mse: 27844.9902\n",
            "Epoch 47/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 28760.9180 - mse: 28760.9180 - val_loss: 26821.6113 - val_mse: 26821.6113\n",
            "Epoch 48/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 28701.6855 - mse: 28701.6816 - val_loss: 26248.5879 - val_mse: 26248.5879\n",
            "Epoch 49/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 28644.7246 - mse: 28644.7246 - val_loss: 26129.5449 - val_mse: 26129.5449\n",
            "Epoch 50/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 28458.5801 - mse: 28458.5801 - val_loss: 28002.6367 - val_mse: 28002.6367\n",
            "Epoch 51/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 28403.1973 - mse: 28403.1973 - val_loss: 26274.5000 - val_mse: 26274.5000\n",
            "Epoch 52/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 28288.6309 - mse: 28288.6309 - val_loss: 26078.9258 - val_mse: 26078.9258\n",
            "Epoch 53/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 28354.7969 - mse: 28354.7969 - val_loss: 26188.6055 - val_mse: 26188.6055\n",
            "Epoch 54/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 28221.3750 - mse: 28221.3750 - val_loss: 26101.4492 - val_mse: 26101.4492\n",
            "Epoch 55/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 28204.2109 - mse: 28204.2109 - val_loss: 25772.1211 - val_mse: 25772.1211\n",
            "Epoch 56/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27918.3750 - mse: 27918.3750 - val_loss: 26360.1602 - val_mse: 26360.1602\n",
            "Epoch 57/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27895.8047 - mse: 27895.8047 - val_loss: 26048.9297 - val_mse: 26048.9297\n",
            "Epoch 58/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 27990.2363 - mse: 27990.2363 - val_loss: 26238.4062 - val_mse: 26238.4062\n",
            "Epoch 59/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27800.9922 - mse: 27800.9922 - val_loss: 25549.3301 - val_mse: 25549.3301\n",
            "Epoch 60/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27908.5449 - mse: 27908.5449 - val_loss: 26085.3594 - val_mse: 26085.3594\n",
            "Epoch 61/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27705.6543 - mse: 27705.6543 - val_loss: 26049.5977 - val_mse: 26049.5977\n",
            "Epoch 62/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 27934.0918 - mse: 27934.0918 - val_loss: 26142.5820 - val_mse: 26142.5820\n",
            "Epoch 63/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27722.8359 - mse: 27722.8359 - val_loss: 25686.2461 - val_mse: 25686.2461\n",
            "Epoch 64/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27542.9043 - mse: 27542.9043 - val_loss: 25621.4746 - val_mse: 25621.4746\n",
            "Epoch 65/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27555.0000 - mse: 27555.0000 - val_loss: 25829.3633 - val_mse: 25829.3633\n",
            "Epoch 66/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27456.1641 - mse: 27456.1641 - val_loss: 25957.8633 - val_mse: 25957.8633\n",
            "Epoch 67/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 27620.1094 - mse: 27620.1074 - val_loss: 25359.4531 - val_mse: 25359.4531\n",
            "Epoch 68/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27416.9590 - mse: 27416.9590 - val_loss: 25709.7637 - val_mse: 25709.7637\n",
            "Epoch 69/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 27508.0762 - mse: 27508.0762 - val_loss: 25820.8809 - val_mse: 25820.8809\n",
            "Epoch 70/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27378.0332 - mse: 27378.0332 - val_loss: 25602.4062 - val_mse: 25602.4062\n",
            "Epoch 71/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 27198.8965 - mse: 27198.8965 - val_loss: 26550.7891 - val_mse: 26550.7891\n",
            "Epoch 72/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27304.4297 - mse: 27304.4297 - val_loss: 25545.8398 - val_mse: 25545.8398\n",
            "Epoch 73/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27221.2461 - mse: 27221.2461 - val_loss: 25352.8848 - val_mse: 25352.8848\n",
            "Epoch 74/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27174.8672 - mse: 27174.8672 - val_loss: 25351.0391 - val_mse: 25351.0391\n",
            "Epoch 75/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27159.3086 - mse: 27159.3086 - val_loss: 25900.1855 - val_mse: 25900.1855\n",
            "Epoch 76/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 27308.8809 - mse: 27308.8809 - val_loss: 25194.1289 - val_mse: 25194.1309\n",
            "Epoch 77/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27170.6172 - mse: 27170.6172 - val_loss: 25860.0215 - val_mse: 25860.0215\n",
            "Epoch 78/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 27023.9805 - mse: 27023.9805 - val_loss: 25740.6992 - val_mse: 25740.6992\n",
            "Epoch 79/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26907.9512 - mse: 26907.9512 - val_loss: 25578.5254 - val_mse: 25578.5254\n",
            "Epoch 80/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 27173.8223 - mse: 27173.8223 - val_loss: 25678.1250 - val_mse: 25678.1250\n",
            "Epoch 81/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26934.2031 - mse: 26934.2031 - val_loss: 25659.8613 - val_mse: 25659.8613\n",
            "Epoch 82/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 27102.6348 - mse: 27102.6348 - val_loss: 25327.9863 - val_mse: 25327.9863\n",
            "Epoch 83/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26905.0117 - mse: 26905.0117 - val_loss: 25311.1367 - val_mse: 25311.1367\n",
            "Epoch 84/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26970.2734 - mse: 26970.2715 - val_loss: 25237.3418 - val_mse: 25237.3418\n",
            "Epoch 85/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26911.7871 - mse: 26911.7871 - val_loss: 25254.1777 - val_mse: 25254.1777\n",
            "Epoch 86/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26811.8652 - mse: 26811.8652 - val_loss: 25459.4785 - val_mse: 25459.4785\n",
            "Epoch 87/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26974.9199 - mse: 26974.9199 - val_loss: 25489.6445 - val_mse: 25489.6445\n",
            "Epoch 88/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26767.2480 - mse: 26767.2480 - val_loss: 25563.0352 - val_mse: 25563.0352\n",
            "Epoch 89/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 26809.4062 - mse: 26809.4062 - val_loss: 26247.6309 - val_mse: 26247.6309\n",
            "Epoch 90/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26811.4844 - mse: 26811.4844 - val_loss: 25144.8145 - val_mse: 25144.8145\n",
            "Epoch 91/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26654.9980 - mse: 26654.9980 - val_loss: 25217.6270 - val_mse: 25217.6270\n",
            "Epoch 92/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26694.8105 - mse: 26694.8105 - val_loss: 25295.2812 - val_mse: 25295.2812\n",
            "Epoch 93/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 26776.0020 - mse: 26776.0020 - val_loss: 25395.5391 - val_mse: 25395.5391\n",
            "Epoch 94/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26447.5176 - mse: 26447.5176 - val_loss: 25897.3691 - val_mse: 25897.3691\n",
            "Epoch 95/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26658.5625 - mse: 26658.5645 - val_loss: 25191.7930 - val_mse: 25191.7930\n",
            "Epoch 96/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26608.4473 - mse: 26608.4473 - val_loss: 25249.1836 - val_mse: 25249.1836\n",
            "Epoch 97/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 26713.8203 - mse: 26713.8242 - val_loss: 25188.6738 - val_mse: 25188.6738\n",
            "Epoch 98/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26424.2832 - mse: 26424.2832 - val_loss: 24916.0156 - val_mse: 24916.0156\n",
            "Epoch 99/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26512.1328 - mse: 26512.1328 - val_loss: 25736.7773 - val_mse: 25736.7773\n",
            "Epoch 100/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26567.0215 - mse: 26567.0215 - val_loss: 25223.7891 - val_mse: 25223.7891\n",
            "Epoch 101/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26579.9316 - mse: 26579.9316 - val_loss: 25785.3320 - val_mse: 25785.3301\n",
            "Epoch 102/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26533.0684 - mse: 26533.0684 - val_loss: 25124.4258 - val_mse: 25124.4258\n",
            "Epoch 103/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26573.4512 - mse: 26573.4531 - val_loss: 25044.4941 - val_mse: 25044.4941\n",
            "Epoch 104/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26517.7363 - mse: 26517.7363 - val_loss: 25150.4863 - val_mse: 25150.4863\n",
            "Epoch 105/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26485.5918 - mse: 26485.5918 - val_loss: 25077.2695 - val_mse: 25077.2695\n",
            "Epoch 106/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26500.4473 - mse: 26500.4473 - val_loss: 25329.4805 - val_mse: 25329.4805\n",
            "Epoch 107/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26252.6328 - mse: 26252.6328 - val_loss: 25657.0195 - val_mse: 25657.0195\n",
            "Epoch 108/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26351.9883 - mse: 26351.9883 - val_loss: 25050.0840 - val_mse: 25050.0840\n",
            "Epoch 109/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26462.5820 - mse: 26462.5820 - val_loss: 25158.0781 - val_mse: 25158.0781\n",
            "Epoch 110/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26316.5625 - mse: 26316.5625 - val_loss: 25186.3496 - val_mse: 25186.3496\n",
            "Epoch 111/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 26486.3867 - mse: 26486.3867 - val_loss: 25120.9355 - val_mse: 25120.9355\n",
            "Epoch 112/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26325.7969 - mse: 26325.7949 - val_loss: 25351.5293 - val_mse: 25351.5293\n",
            "Epoch 113/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26252.3027 - mse: 26252.3027 - val_loss: 25247.4004 - val_mse: 25247.4004\n",
            "Epoch 114/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26384.4980 - mse: 26384.4980 - val_loss: 25038.4316 - val_mse: 25038.4316\n",
            "Epoch 115/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26146.8887 - mse: 26146.8887 - val_loss: 25027.7207 - val_mse: 25027.7207\n",
            "Epoch 116/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26276.4844 - mse: 26276.4844 - val_loss: 25909.8535 - val_mse: 25909.8535\n",
            "Epoch 117/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26283.7832 - mse: 26283.7832 - val_loss: 24951.8691 - val_mse: 24951.8691\n",
            "Epoch 118/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26361.8848 - mse: 26361.8848 - val_loss: 25051.8633 - val_mse: 25051.8652\n",
            "Epoch 119/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26138.8750 - mse: 26138.8750 - val_loss: 25254.1953 - val_mse: 25254.1953\n",
            "Epoch 120/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26159.3535 - mse: 26159.3535 - val_loss: 25923.0430 - val_mse: 25923.0430\n",
            "Epoch 121/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26193.8828 - mse: 26193.8828 - val_loss: 25902.9180 - val_mse: 25902.9180\n",
            "Epoch 122/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26203.5488 - mse: 26203.5488 - val_loss: 25039.7227 - val_mse: 25039.7227\n",
            "Epoch 123/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26197.5312 - mse: 26197.5312 - val_loss: 25045.3613 - val_mse: 25045.3613\n",
            "Epoch 124/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26108.3809 - mse: 26108.3828 - val_loss: 25093.3340 - val_mse: 25093.3340\n",
            "Epoch 125/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26235.9180 - mse: 26235.9180 - val_loss: 24816.6875 - val_mse: 24816.6875\n",
            "Epoch 126/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26014.1328 - mse: 26014.1328 - val_loss: 24928.4082 - val_mse: 24928.4082\n",
            "Epoch 127/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26168.2930 - mse: 26168.2930 - val_loss: 25378.2891 - val_mse: 25378.2891\n",
            "Epoch 128/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26098.5625 - mse: 26098.5625 - val_loss: 24893.6953 - val_mse: 24893.6953\n",
            "Epoch 129/200\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 26040.2285 - mse: 26040.2285 - val_loss: 24818.0664 - val_mse: 24818.0664\n",
            "Epoch 130/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26087.6504 - mse: 26087.6504 - val_loss: 25366.2598 - val_mse: 25366.2598\n",
            "Epoch 131/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26010.4590 - mse: 26010.4570 - val_loss: 24956.4082 - val_mse: 24956.4082\n",
            "Epoch 132/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25979.9355 - mse: 25979.9355 - val_loss: 25192.2168 - val_mse: 25192.2168\n",
            "Epoch 133/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26005.1855 - mse: 26005.1855 - val_loss: 25316.2227 - val_mse: 25316.2227\n",
            "Epoch 134/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26092.3496 - mse: 26092.3496 - val_loss: 24941.1543 - val_mse: 24941.1543\n",
            "Epoch 135/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26043.1562 - mse: 26043.1562 - val_loss: 24933.6934 - val_mse: 24933.6934\n",
            "Epoch 136/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26029.3867 - mse: 26029.3867 - val_loss: 24829.8203 - val_mse: 24829.8203\n",
            "Epoch 137/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 26004.2246 - mse: 26004.2246 - val_loss: 25099.4336 - val_mse: 25099.4336\n",
            "Epoch 138/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25948.6660 - mse: 25948.6660 - val_loss: 24849.0137 - val_mse: 24849.0137\n",
            "Epoch 139/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 25953.3652 - mse: 25953.3652 - val_loss: 25269.6309 - val_mse: 25269.6309\n",
            "Epoch 140/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25972.3398 - mse: 25972.3398 - val_loss: 25265.6836 - val_mse: 25265.6836\n",
            "Epoch 141/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 25934.3809 - mse: 25934.3809 - val_loss: 25165.1973 - val_mse: 25165.1973\n",
            "Epoch 142/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 25941.5586 - mse: 25941.5586 - val_loss: 25294.1211 - val_mse: 25294.1211\n",
            "Epoch 143/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25873.5273 - mse: 25873.5273 - val_loss: 25292.1641 - val_mse: 25292.1641\n",
            "Epoch 144/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 26021.7246 - mse: 26021.7246 - val_loss: 24968.0371 - val_mse: 24968.0371\n",
            "Epoch 145/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25982.9316 - mse: 25982.9316 - val_loss: 25434.5957 - val_mse: 25434.5977\n",
            "Epoch 146/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 25975.9805 - mse: 25975.9805 - val_loss: 25266.9766 - val_mse: 25266.9766\n",
            "Epoch 147/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25799.2441 - mse: 25799.2422 - val_loss: 25308.7480 - val_mse: 25308.7480\n",
            "Epoch 148/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 26032.7734 - mse: 26032.7734 - val_loss: 25175.2246 - val_mse: 25175.2246\n",
            "Epoch 149/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 25971.4102 - mse: 25971.4102 - val_loss: 25088.6777 - val_mse: 25088.6777\n",
            "Epoch 150/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 25637.6758 - mse: 25637.6758 - val_loss: 25136.7441 - val_mse: 25136.7441\n",
            "Epoch 151/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25765.4648 - mse: 25765.4648 - val_loss: 24759.7676 - val_mse: 24759.7676\n",
            "Epoch 152/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25813.5020 - mse: 25813.5020 - val_loss: 24844.5000 - val_mse: 24844.5000\n",
            "Epoch 153/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 25843.3086 - mse: 25843.3086 - val_loss: 24935.4375 - val_mse: 24935.4375\n",
            "Epoch 154/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25710.0449 - mse: 25710.0449 - val_loss: 25084.7324 - val_mse: 25084.7324\n",
            "Epoch 155/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25722.6777 - mse: 25722.6777 - val_loss: 24982.5586 - val_mse: 24982.5586\n",
            "Epoch 156/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25705.7793 - mse: 25705.7793 - val_loss: 25086.7227 - val_mse: 25086.7227\n",
            "Epoch 157/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25818.6621 - mse: 25818.6621 - val_loss: 24995.0625 - val_mse: 24995.0625\n",
            "Epoch 158/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25744.3438 - mse: 25744.3418 - val_loss: 24855.7988 - val_mse: 24855.7988\n",
            "Epoch 159/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25630.9082 - mse: 25630.9082 - val_loss: 24860.9785 - val_mse: 24860.9785\n",
            "Epoch 160/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25791.9336 - mse: 25791.9336 - val_loss: 24910.8984 - val_mse: 24910.8984\n",
            "Epoch 161/200\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 25594.3359 - mse: 25594.3359 - val_loss: 24891.5547 - val_mse: 24891.5547\n",
            "Epoch 162/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25652.4668 - mse: 25652.4668 - val_loss: 25161.4824 - val_mse: 25161.4824\n",
            "Epoch 163/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25804.8906 - mse: 25804.8906 - val_loss: 24990.2891 - val_mse: 24990.2891\n",
            "Epoch 164/200\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 25648.2363 - mse: 25648.2383 - val_loss: 25113.4492 - val_mse: 25113.4492\n",
            "Epoch 165/200\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 25772.3105 - mse: 25772.3086 - val_loss: 24995.7578 - val_mse: 24995.7578\n",
            "Epoch 166/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25713.0273 - mse: 25713.0273 - val_loss: 24872.8145 - val_mse: 24872.8145\n",
            "Epoch 167/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 25663.6816 - mse: 25663.6816 - val_loss: 24907.8242 - val_mse: 24907.8223\n",
            "Epoch 168/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25663.9297 - mse: 25663.9297 - val_loss: 25033.1641 - val_mse: 25033.1641\n",
            "Epoch 169/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25691.2090 - mse: 25691.2090 - val_loss: 24914.6270 - val_mse: 24914.6270\n",
            "Epoch 170/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25489.3535 - mse: 25489.3535 - val_loss: 24992.8691 - val_mse: 24992.8672\n",
            "Epoch 171/200\n",
            "2560/2560 [==============================] - 17s 6ms/step - loss: 25728.5762 - mse: 25728.5762 - val_loss: 25094.9453 - val_mse: 25094.9453\n",
            "Epoch 172/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25593.3652 - mse: 25593.3652 - val_loss: 24760.5195 - val_mse: 24760.5195\n",
            "Epoch 173/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 25672.9102 - mse: 25672.9121 - val_loss: 25251.7324 - val_mse: 25251.7324\n",
            "Epoch 174/200\n",
            "2560/2560 [==============================] - 15s 6ms/step - loss: 25547.1328 - mse: 25547.1328 - val_loss: 24838.6152 - val_mse: 24838.6152\n",
            "Epoch 175/200\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 25560.9180 - mse: 25560.9180 - val_loss: 24942.6758 - val_mse: 24942.6758\n",
            "Epoch 176/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25575.1211 - mse: 25575.1211 - val_loss: 25080.4297 - val_mse: 25080.4297\n",
            "Epoch 177/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25617.0781 - mse: 25617.0781 - val_loss: 24678.0996 - val_mse: 24678.0996\n",
            "Epoch 178/200\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 25585.3496 - mse: 25585.3496 - val_loss: 24954.0254 - val_mse: 24954.0254\n",
            "Epoch 179/200\n",
            "2560/2560 [==============================] - 17s 6ms/step - loss: 25596.1387 - mse: 25596.1387 - val_loss: 25051.1172 - val_mse: 25051.1172\n",
            "Epoch 180/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25651.4863 - mse: 25651.4863 - val_loss: 25083.9297 - val_mse: 25083.9297\n",
            "Epoch 181/200\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 25469.4023 - mse: 25469.4023 - val_loss: 24617.5820 - val_mse: 24617.5820\n",
            "Epoch 182/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25549.7891 - mse: 25549.7891 - val_loss: 25309.2520 - val_mse: 25309.2520\n",
            "Epoch 183/200\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 25553.0352 - mse: 25553.0352 - val_loss: 24908.7168 - val_mse: 24908.7168\n",
            "Epoch 184/200\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 25620.0684 - mse: 25620.0684 - val_loss: 25165.5605 - val_mse: 25165.5605\n",
            "Epoch 185/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25528.4980 - mse: 25528.4980 - val_loss: 24922.7246 - val_mse: 24922.7246\n",
            "Epoch 186/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25511.5273 - mse: 25511.5273 - val_loss: 24775.6641 - val_mse: 24775.6582\n",
            "Epoch 187/200\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 25411.3848 - mse: 25411.3848 - val_loss: 24791.4961 - val_mse: 24791.4941\n",
            "Epoch 188/200\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 25468.8359 - mse: 25468.8359 - val_loss: 25029.3809 - val_mse: 25029.3809\n",
            "Epoch 189/200\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 25477.1719 - mse: 25477.1719 - val_loss: 24754.9434 - val_mse: 24754.9434\n",
            "Epoch 190/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 25443.6875 - mse: 25443.6875 - val_loss: 24923.6172 - val_mse: 24923.6172\n",
            "Epoch 191/200\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 25396.2402 - mse: 25396.2402 - val_loss: 24853.4785 - val_mse: 24853.4785\n",
            "Epoch 192/200\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 25301.6738 - mse: 25301.6738 - val_loss: 24820.4707 - val_mse: 24820.4707\n",
            "Epoch 193/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 25480.0527 - mse: 25480.0527 - val_loss: 24825.9414 - val_mse: 24825.9414\n",
            "Epoch 194/200\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 25338.8262 - mse: 25338.8262 - val_loss: 25199.6582 - val_mse: 25199.6582\n",
            "Epoch 195/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 25447.8164 - mse: 25447.8164 - val_loss: 25023.0332 - val_mse: 25023.0332\n",
            "Epoch 196/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 25526.5273 - mse: 25526.5273 - val_loss: 24742.0410 - val_mse: 24742.0410\n",
            "Epoch 197/200\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 25555.6387 - mse: 25555.6387 - val_loss: 24797.6270 - val_mse: 24797.6270\n",
            "Epoch 198/200\n",
            "2560/2560 [==============================] - 20s 8ms/step - loss: 25236.1328 - mse: 25236.1328 - val_loss: 24741.8184 - val_mse: 24741.8184\n",
            "Epoch 199/200\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 25469.5488 - mse: 25469.5488 - val_loss: 24951.4375 - val_mse: 24951.4375\n",
            "Epoch 200/200\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 25441.4668 - mse: 25441.4668 - val_loss: 24823.8320 - val_mse: 24823.8301\n",
            "1055/1055 [==============================] - 3s 3ms/step\n",
            "MSE: 157.383, R2: 0.789\n",
            "46/46 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Dense, BatchNormalization, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Read data\n",
        "bikes = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv')\n",
        "\n",
        "# Handle missing values\n",
        "bikes['hr'] = bikes['hr'].fillna(bikes['hr'].shift(1) + 1)\n",
        "\n",
        "# Create total_users feature\n",
        "bikes[\"total_users\"] = bikes[\"casual\"] + bikes[\"registered\"]\n",
        "\n",
        "# Split features and target\n",
        "y = bikes['total_users']\n",
        "X = bikes.drop(columns=['casual', 'registered', 'total_users', 'dteday'])\n",
        "\n",
        "# Normalize data\n",
        "norm = MinMaxScaler().fit(X)\n",
        "X_norm = norm.transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define model\n",
        "model = Sequential([\n",
        "    Dense(512, input_dim=X_train.shape[1], activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=['mse'])\n",
        "\n",
        "# Early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=30)\n",
        "\n",
        "# Model training\n",
        "history = model.fit(X_train, y_train, epochs=200, validation_split=0.35, batch_size=20,\n",
        "                    callbacks=[early_stop], shuffle=True, verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "predictions = model.predict(X_test)\n",
        "result = mean_squared_error(y_test, predictions, squared=False)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(f'MSE: {result:.3f}, R2: {r2:.3f}')\n",
        "\n",
        "# Save predictions\n",
        "bikesTest = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes_december.csv')\n",
        "bikesTest = bikesTest.drop(columns=['dteday'])\n",
        "\n",
        "bikesTest_norm = norm.transform(bikesTest)\n",
        "holdout_predictions = model.predict(bikesTest_norm)\n",
        "rounded_predictions = np.round(holdout_predictions)\n",
        "np.savetxt(\"team1-module4-predictions.csv\", rounded_predictions, delimiter=\",\", header=\"predictions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTfI9KPXlKus",
        "outputId": "40ca2704-a55a-4b97-c097-dd0a0570c3be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3150/3150 [==============================] - 17s 5ms/step - loss: 72751.1484 - mse: 72751.1484 - val_loss: 46789.9648 - val_mse: 46789.9648\n",
            "Epoch 2/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 53267.4492 - mse: 53267.4492 - val_loss: 40871.7930 - val_mse: 40871.7930\n",
            "Epoch 3/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 49709.5742 - mse: 49709.5742 - val_loss: 35479.0195 - val_mse: 35479.0195\n",
            "Epoch 4/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 47070.6211 - mse: 47070.6211 - val_loss: 34560.5977 - val_mse: 34560.5977\n",
            "Epoch 5/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 46032.6719 - mse: 46032.6719 - val_loss: 32639.6055 - val_mse: 32639.6055\n",
            "Epoch 6/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 44986.6562 - mse: 44986.6562 - val_loss: 32781.4961 - val_mse: 32781.4961\n",
            "Epoch 7/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 44542.8281 - mse: 44542.8320 - val_loss: 32826.1094 - val_mse: 32826.1094\n",
            "Epoch 8/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 44402.4805 - mse: 44402.4805 - val_loss: 32263.3730 - val_mse: 32263.3730\n",
            "Epoch 9/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 43239.1484 - mse: 43239.1484 - val_loss: 34484.1172 - val_mse: 34484.1172\n",
            "Epoch 10/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 42988.0352 - mse: 42988.0352 - val_loss: 30753.2051 - val_mse: 30753.2051\n",
            "Epoch 11/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 42844.3359 - mse: 42844.3359 - val_loss: 32720.0547 - val_mse: 32720.0547\n",
            "Epoch 12/200\n",
            "3150/3150 [==============================] - 12s 4ms/step - loss: 42094.9805 - mse: 42094.9805 - val_loss: 32035.5762 - val_mse: 32035.5801\n",
            "Epoch 13/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 42080.2891 - mse: 42080.2930 - val_loss: 32875.1172 - val_mse: 32875.1172\n",
            "Epoch 14/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 41506.7500 - mse: 41506.7500 - val_loss: 31625.4102 - val_mse: 31625.4102\n",
            "Epoch 15/200\n",
            "3150/3150 [==============================] - 14s 4ms/step - loss: 41369.2383 - mse: 41369.2383 - val_loss: 29208.6641 - val_mse: 29208.6621\n",
            "Epoch 16/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 41484.7227 - mse: 41484.7227 - val_loss: 30015.1777 - val_mse: 30015.1777\n",
            "Epoch 17/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 40660.3164 - mse: 40660.3164 - val_loss: 30981.8828 - val_mse: 30981.8828\n",
            "Epoch 18/200\n",
            "3150/3150 [==============================] - 14s 4ms/step - loss: 40269.0352 - mse: 40269.0352 - val_loss: 30058.1191 - val_mse: 30058.1191\n",
            "Epoch 19/200\n",
            "3150/3150 [==============================] - 14s 4ms/step - loss: 40750.6133 - mse: 40750.6133 - val_loss: 29811.5371 - val_mse: 29811.5371\n",
            "Epoch 20/200\n",
            "3150/3150 [==============================] - 15s 5ms/step - loss: 40289.7500 - mse: 40289.7461 - val_loss: 29357.7031 - val_mse: 29357.7031\n",
            "Epoch 21/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 40118.4844 - mse: 40118.4844 - val_loss: 29533.3555 - val_mse: 29533.3555\n",
            "Epoch 22/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 39198.0156 - mse: 39198.0156 - val_loss: 29789.5117 - val_mse: 29789.5117\n",
            "Epoch 23/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 39508.5664 - mse: 39508.5664 - val_loss: 32585.7891 - val_mse: 32585.7891\n",
            "Epoch 24/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 39272.1602 - mse: 39272.1602 - val_loss: 29961.7656 - val_mse: 29961.7656\n",
            "Epoch 25/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 39588.7617 - mse: 39588.7617 - val_loss: 29398.1680 - val_mse: 29398.1680\n",
            "Epoch 26/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 38951.3359 - mse: 38951.3359 - val_loss: 30291.8184 - val_mse: 30291.8184\n",
            "Epoch 27/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 38941.6445 - mse: 38941.6445 - val_loss: 29067.9629 - val_mse: 29067.9629\n",
            "Epoch 28/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 38768.7656 - mse: 38768.7617 - val_loss: 29981.5312 - val_mse: 29981.5312\n",
            "Epoch 29/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 38806.9375 - mse: 38806.9375 - val_loss: 29959.0098 - val_mse: 29959.0098\n",
            "Epoch 30/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 38109.2227 - mse: 38109.2227 - val_loss: 32023.2832 - val_mse: 32023.2832\n",
            "Epoch 31/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 38501.8477 - mse: 38501.8477 - val_loss: 30512.9238 - val_mse: 30512.9238\n",
            "Epoch 32/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 38776.9688 - mse: 38776.9688 - val_loss: 30771.1914 - val_mse: 30771.1914\n",
            "Epoch 33/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 37862.0234 - mse: 37862.0234 - val_loss: 29622.1660 - val_mse: 29622.1660\n",
            "Epoch 34/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 38337.5039 - mse: 38337.5039 - val_loss: 28735.2773 - val_mse: 28735.2773\n",
            "Epoch 35/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 38123.7539 - mse: 38123.7539 - val_loss: 28866.1777 - val_mse: 28866.1758\n",
            "Epoch 36/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 37851.4570 - mse: 37851.4570 - val_loss: 28568.4863 - val_mse: 28568.4863\n",
            "Epoch 37/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 38017.4336 - mse: 38017.4336 - val_loss: 28806.3398 - val_mse: 28806.3398\n",
            "Epoch 38/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 37736.8672 - mse: 37736.8672 - val_loss: 29075.3262 - val_mse: 29075.3262\n",
            "Epoch 39/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 37628.9023 - mse: 37628.9023 - val_loss: 28515.2754 - val_mse: 28515.2754\n",
            "Epoch 40/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 37772.0664 - mse: 37772.0664 - val_loss: 28729.0449 - val_mse: 28729.0449\n",
            "Epoch 41/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 37452.5625 - mse: 37452.5625 - val_loss: 29846.0215 - val_mse: 29846.0215\n",
            "Epoch 42/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 37335.0234 - mse: 37335.0234 - val_loss: 28816.0879 - val_mse: 28816.0859\n",
            "Epoch 43/200\n",
            "3150/3150 [==============================] - 14s 4ms/step - loss: 37389.2969 - mse: 37389.2969 - val_loss: 28794.4727 - val_mse: 28794.4727\n",
            "Epoch 44/200\n",
            "3150/3150 [==============================] - 14s 4ms/step - loss: 37130.6016 - mse: 37130.6016 - val_loss: 29453.6113 - val_mse: 29453.6113\n",
            "Epoch 45/200\n",
            "3150/3150 [==============================] - 14s 4ms/step - loss: 37504.0117 - mse: 37504.0117 - val_loss: 30053.6895 - val_mse: 30053.6895\n",
            "Epoch 46/200\n",
            "3150/3150 [==============================] - 15s 5ms/step - loss: 37544.0625 - mse: 37544.0625 - val_loss: 28538.9707 - val_mse: 28538.9707\n",
            "Epoch 47/200\n",
            "3150/3150 [==============================] - 14s 4ms/step - loss: 37311.5312 - mse: 37311.5312 - val_loss: 30174.4629 - val_mse: 30174.4609\n",
            "Epoch 48/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 37566.5742 - mse: 37566.5742 - val_loss: 28478.2754 - val_mse: 28478.2754\n",
            "Epoch 49/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36761.3164 - mse: 36761.3164 - val_loss: 28579.4023 - val_mse: 28579.4023\n",
            "Epoch 50/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 37217.5820 - mse: 37217.5820 - val_loss: 28608.2754 - val_mse: 28608.2754\n",
            "Epoch 51/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36940.0117 - mse: 36940.0117 - val_loss: 28687.6582 - val_mse: 28687.6582\n",
            "Epoch 52/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36886.5781 - mse: 36886.5781 - val_loss: 28828.1055 - val_mse: 28828.1055\n",
            "Epoch 53/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36911.1289 - mse: 36911.1289 - val_loss: 28310.4570 - val_mse: 28310.4570\n",
            "Epoch 54/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36712.4219 - mse: 36712.4219 - val_loss: 28752.9863 - val_mse: 28752.9863\n",
            "Epoch 55/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36733.0273 - mse: 36733.0273 - val_loss: 28550.0000 - val_mse: 28550.0000\n",
            "Epoch 56/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36678.7266 - mse: 36678.7266 - val_loss: 27628.3887 - val_mse: 27628.3887\n",
            "Epoch 57/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36552.9141 - mse: 36552.9141 - val_loss: 28006.8535 - val_mse: 28006.8535\n",
            "Epoch 58/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36241.2695 - mse: 36241.2695 - val_loss: 28329.5605 - val_mse: 28329.5605\n",
            "Epoch 59/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36870.0977 - mse: 36870.0977 - val_loss: 28192.2539 - val_mse: 28192.2539\n",
            "Epoch 60/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36965.9023 - mse: 36965.9023 - val_loss: 29494.7031 - val_mse: 29494.7031\n",
            "Epoch 61/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36370.4453 - mse: 36370.4453 - val_loss: 28731.5215 - val_mse: 28731.5215\n",
            "Epoch 62/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36638.4844 - mse: 36638.4844 - val_loss: 28121.5645 - val_mse: 28121.5645\n",
            "Epoch 63/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36464.0781 - mse: 36464.0781 - val_loss: 28734.2539 - val_mse: 28734.2539\n",
            "Epoch 64/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36163.6016 - mse: 36163.6016 - val_loss: 28758.3711 - val_mse: 28758.3711\n",
            "Epoch 65/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36380.6328 - mse: 36380.6328 - val_loss: 28787.6582 - val_mse: 28787.6582\n",
            "Epoch 66/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36291.5117 - mse: 36291.5117 - val_loss: 29210.4980 - val_mse: 29210.4980\n",
            "Epoch 67/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36182.4844 - mse: 36182.4805 - val_loss: 28834.2246 - val_mse: 28834.2246\n",
            "Epoch 68/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36120.1484 - mse: 36120.1484 - val_loss: 27820.5117 - val_mse: 27820.5117\n",
            "Epoch 69/200\n",
            "3150/3150 [==============================] - 15s 5ms/step - loss: 36492.2461 - mse: 36492.2461 - val_loss: 29176.7656 - val_mse: 29176.7656\n",
            "Epoch 70/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36323.3164 - mse: 36323.3164 - val_loss: 28579.1074 - val_mse: 28579.1074\n",
            "Epoch 71/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 35918.5469 - mse: 35918.5469 - val_loss: 28625.7168 - val_mse: 28625.7168\n",
            "Epoch 72/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 36136.1602 - mse: 36136.1602 - val_loss: 28128.3379 - val_mse: 28128.3379\n",
            "Epoch 73/200\n",
            "3150/3150 [==============================] - 13s 4ms/step - loss: 35915.9102 - mse: 35915.9102 - val_loss: 28766.1816 - val_mse: 28766.1816\n",
            "Epoch 74/200\n",
            "3150/3150 [==============================] - 14s 4ms/step - loss: 35899.7773 - mse: 35899.7773 - val_loss: 28164.0020 - val_mse: 28164.0020\n",
            "Epoch 75/200\n",
            "3150/3150 [==============================] - 14s 4ms/step - loss: 35944.9727 - mse: 35944.9688 - val_loss: 30085.5957 - val_mse: 30085.5957\n",
            "Epoch 76/200\n",
            "3150/3150 [==============================] - 14s 4ms/step - loss: 35930.5039 - mse: 35930.5039 - val_loss: 29122.6582 - val_mse: 29122.6562\n",
            "1055/1055 [==============================] - 2s 2ms/step\n",
            "MSE: 27522.186, R2: 0.766\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Read data\n",
        "bikes = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv')\n",
        "\n",
        "# Handle missing values\n",
        "bikes['hr'] = bikes['hr'].fillna(method='ffill')\n",
        "\n",
        "# Create total_users feature\n",
        "bikes[\"total_users\"] = bikes[\"casual\"] + bikes[\"registered\"]\n",
        "\n",
        "# Split features and target\n",
        "y = bikes['total_users']\n",
        "X = bikes.drop(columns=['casual', 'registered', 'total_users', 'dteday'])\n",
        "\n",
        "# Normalize data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(256, input_dim=X_train.shape[1], activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.00.05)\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=['mse'])\n",
        "\n",
        "# Early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "# Model training\n",
        "history = model.fit(X_train, y_train, epochs=200, validation_split=0.2, batch_size=20, callbacks=[early_stop], verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "predictions = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(f'MSE: {mse:.3f}, R2: {r2:.3f}')\n",
        "\n",
        "# Save predictions\n",
        "bikesTest = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/biking_holdout_test_mini.csv')\n",
        "bikesTest = bikesTest.drop(columns=['dteday'])\n",
        "bikesTest_scaled = scaler.transform(bikesTest)\n",
        "holdout_predictions = model.predict(bikesTest_scaled)\n",
        "rounded_predictions = np.round(holdout_predictions)\n",
        "np.savetxt(\"best_model_predictions.csv\", rounded_predictions, delimiter=\",\", header=\"predictions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF3homzRqb7t",
        "outputId": "78cf02a7-dd73-4dfb-b5fa-8ecf1b4214c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2560/2560 [==============================] - 21s 7ms/step - loss: 74730.0312 - mse: 74730.0312 - val_loss: 43248.1328 - val_mse: 43248.1328\n",
            "Epoch 2/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 54108.9102 - mse: 54108.9102 - val_loss: 37496.6641 - val_mse: 37496.6641\n",
            "Epoch 3/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 50487.9727 - mse: 50487.9727 - val_loss: 35632.9062 - val_mse: 35632.9023\n",
            "Epoch 4/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 47141.8906 - mse: 47141.8906 - val_loss: 36880.1289 - val_mse: 36880.1289\n",
            "Epoch 5/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 45601.9414 - mse: 45601.9414 - val_loss: 32050.3398 - val_mse: 32050.3398\n",
            "Epoch 6/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 44294.7422 - mse: 44294.7422 - val_loss: 32394.8125 - val_mse: 32394.8125\n",
            "Epoch 7/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 43405.3984 - mse: 43405.3984 - val_loss: 29517.5938 - val_mse: 29517.5938\n",
            "Epoch 8/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 43100.7695 - mse: 43100.7695 - val_loss: 33509.2461 - val_mse: 33509.2461\n",
            "Epoch 9/100\n",
            "2560/2560 [==============================] - 20s 8ms/step - loss: 42697.7266 - mse: 42697.7266 - val_loss: 30783.5078 - val_mse: 30783.5078\n",
            "Epoch 10/100\n",
            "2560/2560 [==============================] - 24s 9ms/step - loss: 42068.3398 - mse: 42068.3398 - val_loss: 33915.6758 - val_mse: 33915.6758\n",
            "Epoch 11/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 41564.5352 - mse: 41564.5352 - val_loss: 31465.5293 - val_mse: 31465.5293\n",
            "Epoch 12/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 40891.8789 - mse: 40891.8789 - val_loss: 29317.6719 - val_mse: 29317.6719\n",
            "Epoch 13/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 40766.9297 - mse: 40766.9297 - val_loss: 30222.0449 - val_mse: 30222.0449\n",
            "Epoch 14/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 40536.2656 - mse: 40536.2656 - val_loss: 29820.2871 - val_mse: 29820.2871\n",
            "Epoch 15/100\n",
            "2560/2560 [==============================] - 20s 8ms/step - loss: 39948.6523 - mse: 39948.6523 - val_loss: 30145.2500 - val_mse: 30145.2500\n",
            "Epoch 16/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 39557.3555 - mse: 39557.3555 - val_loss: 29388.8594 - val_mse: 29388.8594\n",
            "Epoch 17/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 39030.2383 - mse: 39030.2383 - val_loss: 30715.7031 - val_mse: 30715.7031\n",
            "Epoch 18/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 38745.0039 - mse: 38745.0039 - val_loss: 32141.6641 - val_mse: 32141.6641\n",
            "Epoch 19/100\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 38872.5195 - mse: 38872.5195 - val_loss: 29031.2969 - val_mse: 29031.2969\n",
            "Epoch 20/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 38539.5508 - mse: 38539.5508 - val_loss: 28591.9277 - val_mse: 28591.9277\n",
            "Epoch 21/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 38441.9375 - mse: 38441.9375 - val_loss: 29026.2715 - val_mse: 29026.2715\n",
            "Epoch 22/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 37861.7812 - mse: 37861.7812 - val_loss: 31534.0703 - val_mse: 31534.0703\n",
            "Epoch 23/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 38064.1562 - mse: 38064.1562 - val_loss: 28618.0723 - val_mse: 28618.0723\n",
            "Epoch 24/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 37704.4688 - mse: 37704.4688 - val_loss: 28185.2520 - val_mse: 28185.2520\n",
            "Epoch 25/100\n",
            "2560/2560 [==============================] - 19s 8ms/step - loss: 37782.8320 - mse: 37782.8320 - val_loss: 29743.0820 - val_mse: 29743.0820\n",
            "Epoch 26/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 37434.2734 - mse: 37434.2695 - val_loss: 31777.0918 - val_mse: 31777.0879\n",
            "Epoch 27/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 37830.7305 - mse: 37830.7305 - val_loss: 28344.3418 - val_mse: 28344.3418\n",
            "Epoch 28/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 37176.8242 - mse: 37176.8242 - val_loss: 28365.2832 - val_mse: 28365.2832\n",
            "Epoch 29/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 37317.2617 - mse: 37317.2617 - val_loss: 29109.7891 - val_mse: 29109.7891\n",
            "Epoch 30/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 37176.8164 - mse: 37176.8164 - val_loss: 28007.5391 - val_mse: 28007.5391\n",
            "Epoch 31/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 37035.6094 - mse: 37035.6055 - val_loss: 28048.6309 - val_mse: 28048.6309\n",
            "Epoch 32/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 37131.6953 - mse: 37131.6953 - val_loss: 28038.4277 - val_mse: 28038.4277\n",
            "Epoch 33/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 36463.9062 - mse: 36463.9062 - val_loss: 28706.5957 - val_mse: 28706.5957\n",
            "Epoch 34/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 36444.9844 - mse: 36444.9844 - val_loss: 29134.8086 - val_mse: 29134.8086\n",
            "Epoch 35/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 36462.3594 - mse: 36462.3594 - val_loss: 27927.2578 - val_mse: 27927.2578\n",
            "Epoch 36/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 36215.7383 - mse: 36215.7383 - val_loss: 27517.9883 - val_mse: 27517.9883\n",
            "Epoch 37/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 36321.3164 - mse: 36321.3164 - val_loss: 28748.5605 - val_mse: 28748.5605\n",
            "Epoch 38/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 36686.9531 - mse: 36686.9531 - val_loss: 27646.7637 - val_mse: 27646.7637\n",
            "Epoch 39/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 36294.6602 - mse: 36294.6602 - val_loss: 27758.9102 - val_mse: 27758.9102\n",
            "Epoch 40/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 36450.1328 - mse: 36450.1328 - val_loss: 27685.0723 - val_mse: 27685.0723\n",
            "Epoch 41/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 35831.1055 - mse: 35831.1055 - val_loss: 27633.4824 - val_mse: 27633.4824\n",
            "Epoch 42/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 36051.6172 - mse: 36051.6172 - val_loss: 28391.0195 - val_mse: 28391.0195\n",
            "Epoch 43/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 35520.7344 - mse: 35520.7344 - val_loss: 29203.6445 - val_mse: 29203.6445\n",
            "Epoch 44/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 36193.0742 - mse: 36193.0742 - val_loss: 28453.5332 - val_mse: 28453.5332\n",
            "Epoch 45/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 36031.8398 - mse: 36031.8398 - val_loss: 27728.5000 - val_mse: 27728.5000\n",
            "Epoch 46/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 36148.9883 - mse: 36148.9883 - val_loss: 31727.9629 - val_mse: 31727.9629\n",
            "Epoch 47/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 35832.6016 - mse: 35832.6016 - val_loss: 27450.6699 - val_mse: 27450.6699\n",
            "Epoch 48/100\n",
            "2560/2560 [==============================] - 21s 8ms/step - loss: 35957.9766 - mse: 35957.9766 - val_loss: 28766.2520 - val_mse: 28766.2520\n",
            "Epoch 49/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 35330.5664 - mse: 35330.5664 - val_loss: 29287.1777 - val_mse: 29287.1777\n",
            "Epoch 50/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 35522.0742 - mse: 35522.0742 - val_loss: 27369.6641 - val_mse: 27369.6641\n",
            "Epoch 51/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 35947.8242 - mse: 35947.8242 - val_loss: 28585.3887 - val_mse: 28585.3887\n",
            "Epoch 52/100\n",
            "2560/2560 [==============================] - 21s 8ms/step - loss: 36092.5156 - mse: 36092.5156 - val_loss: 30006.1660 - val_mse: 30006.1660\n",
            "Epoch 53/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 35380.7031 - mse: 35380.7031 - val_loss: 29775.7109 - val_mse: 29775.7109\n",
            "Epoch 54/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 35618.7891 - mse: 35618.7891 - val_loss: 27412.5156 - val_mse: 27412.5156\n",
            "Epoch 55/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 35252.4922 - mse: 35252.4922 - val_loss: 28339.5625 - val_mse: 28339.5625\n",
            "Epoch 56/100\n",
            "2560/2560 [==============================] - 19s 8ms/step - loss: 35290.5430 - mse: 35290.5430 - val_loss: 27297.1973 - val_mse: 27297.1973\n",
            "Epoch 57/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 35710.8086 - mse: 35710.8086 - val_loss: 29046.4922 - val_mse: 29046.4922\n",
            "Epoch 58/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 35268.3047 - mse: 35268.3047 - val_loss: 27724.6035 - val_mse: 27724.6035\n",
            "Epoch 59/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 35181.3438 - mse: 35181.3438 - val_loss: 29843.7617 - val_mse: 29843.7617\n",
            "Epoch 60/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 35374.2734 - mse: 35374.2773 - val_loss: 26622.3398 - val_mse: 26622.3398\n",
            "Epoch 61/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 34663.7305 - mse: 34663.7305 - val_loss: 26999.3477 - val_mse: 26999.3477\n",
            "Epoch 62/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 35294.6016 - mse: 35294.6016 - val_loss: 28411.5020 - val_mse: 28411.5020\n",
            "Epoch 63/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 35233.6094 - mse: 35233.6094 - val_loss: 26948.5293 - val_mse: 26948.5293\n",
            "Epoch 64/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 34883.9062 - mse: 34883.9062 - val_loss: 28670.1152 - val_mse: 28670.1152\n",
            "Epoch 65/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 35024.2539 - mse: 35024.2539 - val_loss: 27946.8477 - val_mse: 27946.8477\n",
            "Epoch 66/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 34543.0312 - mse: 34543.0312 - val_loss: 27623.7617 - val_mse: 27623.7598\n",
            "Epoch 67/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 34704.4922 - mse: 34704.4922 - val_loss: 29457.8594 - val_mse: 29457.8594\n",
            "Epoch 68/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 35253.7578 - mse: 35253.7578 - val_loss: 27551.0820 - val_mse: 27551.0820\n",
            "Epoch 69/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 34883.5742 - mse: 34883.5742 - val_loss: 27201.1953 - val_mse: 27201.1953\n",
            "Epoch 70/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 34785.6992 - mse: 34785.6992 - val_loss: 27835.2305 - val_mse: 27835.2305\n",
            "Epoch 71/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 34830.0117 - mse: 34830.0117 - val_loss: 28222.1191 - val_mse: 28222.1191\n",
            "Epoch 72/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 34589.2422 - mse: 34589.2422 - val_loss: 27389.8477 - val_mse: 27389.8477\n",
            "Epoch 73/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 34572.8945 - mse: 34572.8945 - val_loss: 27867.1680 - val_mse: 27867.1680\n",
            "Epoch 74/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 35038.4414 - mse: 35038.4414 - val_loss: 27362.1719 - val_mse: 27362.1719\n",
            "Epoch 75/100\n",
            "2560/2560 [==============================] - 16s 6ms/step - loss: 34647.1719 - mse: 34647.1758 - val_loss: 28072.7773 - val_mse: 28072.7773\n",
            "Epoch 76/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 34743.3789 - mse: 34743.3867 - val_loss: 28089.1074 - val_mse: 28089.1074\n",
            "Epoch 77/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 34643.0000 - mse: 34643.0000 - val_loss: 27773.1172 - val_mse: 27773.1172\n",
            "Epoch 78/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 34420.8672 - mse: 34420.8672 - val_loss: 27413.3340 - val_mse: 27413.3340\n",
            "Epoch 79/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 34286.3867 - mse: 34286.3828 - val_loss: 27140.4336 - val_mse: 27140.4336\n",
            "Epoch 80/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 34677.1641 - mse: 34677.1641 - val_loss: 27329.8438 - val_mse: 27329.8398\n",
            "Epoch 81/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 34447.3008 - mse: 34447.3008 - val_loss: 27867.3281 - val_mse: 27867.3281\n",
            "Epoch 82/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 33854.1250 - mse: 33854.1250 - val_loss: 27500.2773 - val_mse: 27500.2773\n",
            "Epoch 83/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 34432.0625 - mse: 34432.0625 - val_loss: 27629.6484 - val_mse: 27629.6484\n",
            "Epoch 84/100\n",
            "2560/2560 [==============================] - 17s 7ms/step - loss: 34290.1680 - mse: 34290.1680 - val_loss: 27192.4102 - val_mse: 27192.4102\n",
            "Epoch 85/100\n",
            "2560/2560 [==============================] - 20s 8ms/step - loss: 34412.3750 - mse: 34412.3750 - val_loss: 27321.1074 - val_mse: 27321.1074\n",
            "Epoch 86/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 34336.9297 - mse: 34336.9297 - val_loss: 28046.4863 - val_mse: 28046.4863\n",
            "Epoch 87/100\n",
            "2560/2560 [==============================] - 20s 8ms/step - loss: 34346.6641 - mse: 34346.6641 - val_loss: 27564.4238 - val_mse: 27564.4238\n",
            "Epoch 88/100\n",
            "2560/2560 [==============================] - 18s 7ms/step - loss: 34321.9023 - mse: 34321.9023 - val_loss: 26831.2324 - val_mse: 26831.2324\n",
            "Epoch 89/100\n",
            "2560/2560 [==============================] - 20s 8ms/step - loss: 34004.5586 - mse: 34004.5586 - val_loss: 27769.4863 - val_mse: 27769.4863\n",
            "Epoch 90/100\n",
            "2560/2560 [==============================] - 19s 7ms/step - loss: 34086.0703 - mse: 34086.0781 - val_loss: 27676.5684 - val_mse: 27676.5684\n",
            "1055/1055 [==============================] - 2s 2ms/step\n",
            "MSE: 26874.593, R2: 0.771\n",
            "12/12 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Read data\n",
        "bikes = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv')\n",
        "\n",
        "# Handle missing values\n",
        "bikes['hr'] = bikes['hr'].fillna(method='ffill')\n",
        "\n",
        "# Create total_users feature\n",
        "bikes[\"total_users\"] = bikes[\"casual\"] + bikes[\"registered\"]\n",
        "\n",
        "# Split features and target\n",
        "y = bikes['total_users']\n",
        "X = bikes.drop(columns=['casual', 'registered', 'total_users', 'dteday'])\n",
        "\n",
        "# Normalize data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(512, input_dim=X_train.shape[1], activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=['mse'])\n",
        "\n",
        "# Early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
        "\n",
        "# Model training\n",
        "history = model.fit(X_train, y_train, epochs=100, validation_split=0.35, batch_size=20, callbacks=[early_stop], verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "predictions = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(f'MSE: {mse:.3f}, R2: {r2:.3f}')\n",
        "\n",
        "# Save predictions\n",
        "bikesTest = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/biking_holdout_test_mini.csv')\n",
        "bikesTest = bikesTest.drop(columns=['dteday'])\n",
        "bikesTest_scaled = scaler.transform(bikesTest)\n",
        "holdout_predictions = model.predict(bikesTest_scaled)\n",
        "rounded_predictions = np.round(holdout_predictions)\n",
        "np.savetxt(\"team1-module4-predictions.csv\", rounded_predictions, delimiter=\",\", header=\"predictions\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}